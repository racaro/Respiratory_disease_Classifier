# -*- coding: utf-8 -*-
"""Modelo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dVdXBUWxNjHMFLF8d_cPyg4QfdcZcC1W

### 1.0 Importación Modulos
"""

from google.colab import drive
drive.mount('/content/drive')

path_base = "drive/MyDrive/PROYECTO/Clasificador_Enfermo/"

# Revisar pre-procesamiento - 
# Trabajar con datos imbalanceados -
    # train test split, 
# Generador -/
# Modelo -/
# Resultados
# Hyperparameter tuning

#!pip install tensorflow

import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import sklearn.metrics

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.layers import Dropout, Flatten, Dense 
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.preprocessing.image import ImageDataGenerator

"""### 2.0 Preprocesamiento

"""

train_datagen = ImageDataGenerator(
    rescale = 1./255,
    shear_range = 0.2,
    zoom_range = 0.2,
    validation_split=0.2
)

path_generator = "/content/drive/MyDrive/PROYECTO/Respiratory_Sound_Database/Respiratory_Sound_Database/Respiratory_Sound_Database/Enfermedades"

path_generator

# Generador de datos, forma en la que se imputan los datos en la red neuronal a traves de set de imagenes...
train_generator = train_datagen.flow_from_directory(
    path_generator,
    subset= "training",
    target_size = (288,216),
    color_mode = "rgb",
    batch_size = 32,
    class_mode = "categorical",
    shuffle = True
)

validation_generator = train_datagen.flow_from_directory(
     path_generator,
    subset= "validation",
    target_size = (288,216),
    batch_size = 32,
    class_mode = "categorical",
    shuffle = True
)

"""Le damos imagenes y nos predice una categoria
    - Le pasamos las imagenes como matrices --> (224,224,3)
    - Las categorias: Asthma:1

8 categorias
   - Darle al modelo una forma sencilla de representar las categorias
   - Asthma:1, COPD: 2, Bronquitis:3 ... (Numerical encoding)

Nuestro modelo si le damos una categorio que es 8 y otra que es 1, le va a dar mas importancia al 8 que al 1 por que es mayor

One-hot encoding 
    - Que cada etiqueta tenga el mismo valor aritmetico
    - Separar entre clases es la posicion
    - [1, 0,0] Asthma
    - [0,1,0] COPD
    - [0,0,1] Bronquitis
"""

# Etiqueta categorica real
transformador =train_generator.class_indices

transformador

y_test_etiquetas

transformador_turned = {value : key for (key, value) in transformador.items()}

transformador_turned

for i in range(10):
    img,label = validation_generator.next()
    print(img.shape)
    plt.imshow(img[0])
    print(transformador_turned[np.argmax(label)])
    plt.show()

"""### 3.0 Modelo"""

model = Sequential()

model.add(Conv2D(32,(3,3), input_shape=(288,216,3), activation="relu"))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(32,(3,3), activation="relu"))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(64,(3,3), activation="relu"))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(64,(3,3), activation="relu"))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Flatten())
model.add(Dense(64,activation="relu"))
model.add(Dense(8,activation="softmax"))

model.compile(loss= "categorical_crossentropy", optimizer= "rmsprop", metrics=["accuracy"])
historial=model.fit(train_generator,validation_data= validation_generator,epochs=20)

plt.xlabel('EPOCH')
plt.ylabel('MAGNITUD DE PÉRDIDA')
plt.plot(historial.history['loss'])
#funcion de pérdida en cada epoch

model.save("drive/MyDrive/PROYECTO/modelos/modelo_grande_enfermedad.h5")

model.evaluate(validation_generator)

"""### 4.0 Hyperparameter tuning"""

!pip install -q -U keras-tuner

import keras_tuner as kt

def model_builder(hp):
  model = Sequential()

  #Cambiamos numero de filtros 
  hp_numero_nodos_primera = hp.Int("units",min_value=64,max_value=128,step=16)

  model.add(Conv2D(hp_numero_nodos_primera,(3,3), input_shape=(288,216,3), activation="relu"))
  model.add(MaxPooling2D(pool_size=(2,2)))

  hp_numero_nodos_segunda = hp.Int("units",min_value=32,max_value=64,step=16)
  model.add(Conv2D(hp_numero_nodos_segunda,(3,3), activation="relu"))
  model.add(MaxPooling2D(pool_size=(2,2)))

  hp_numero_nodos_tercera = hp.Int("units",min_value=16,max_value=32,step=8)
  model.add(Conv2D(hp_numero_nodos_tercera,(3,3), activation="relu"))
  model.add(MaxPooling2D(pool_size=(2,2)))

  hp_numero_nodos_cuarta = hp.Int("units",min_value=8,max_value=16,step=4)
  model.add(Conv2D(hp_numero_nodos_cuarta,(3,3), activation="relu"))
  model.add(MaxPooling2D(pool_size=(2,2)))
  model.add(Flatten())
  hp_numero_nodos_quinta = hp.Int("units",min_value=64,max_value=128,step=16)
  model.add(Dense(64,activation="relu"))
  model.add(Dense(1,activation="sigmoid"))

  lr = hp.Choice("learning_rate",values=[1e-1,1e-2,1e-3,1e-4])
  model.compile(loss= "binary_crossentropy", optimizer= tf.keras.optimizers.Adam(learning_rate=lr), metrics=["accuracy"])
  return model
  #model.fit(train_generator,validation_data= validation_generator,epochs=10)

tuner = kt.Hyperband(model_builder,
                     objective="accuracy",
                     max_epochs=5,
                     directory="my_dir",
                     project_name="proyecto2")

stop_early = tf.keras.callbacks.EarlyStopping(monitor="accuracy",patience=5)

tuner.search(train_generator,epochs=5,callbacks=[stop_early],validation_data=validation_generator)
best_model = tuner.get_best_models()[0]

best_model.save("drive/MyDrive/PROYECTO/modelos/modelo_enfermedades_hp.h5")

"""### 5.0 Resultados directos"""

import tensorflow
from tensorflow.keras.models import load_model

model = load_model("drive/MyDrive/Proyecto/modelos/modelo_enfermedades_hp.h5")
y_pred = model.predict(validation_generator)
y_pred = np.argmax(y_pred,axis=1)
y_pred_etiquetas = []
for i in validation_generator.classes:
    y_pred_etiquetas.append(transformador[y_pred[i]])

print(y_pred_etiquetas)
print(y_test_etiquetas)

validation_generator.classes

validation_generator.classes.shape

resultados = pd.DataFrame([validation_generator.classes,y_pred])

resultados = resultados.T
resultados.columns = ["y_test","y_pred"]
resultados

resultados_etiquetas =pd.DataFrame([y_test_etiquetas,y_pred_etiquetas])
resultados_etiquetas = resultados_etiquetas.T
resultados_etiquetas.columns = ["y_test","y_pred"]
resultados_etiquetas



###2.0 Metricas

from sklearn.metrics import auc,roc_curve,confusion_matrix,ConfusionMatrixDisplay

cm = confusion_matrix(validation_generator.classes,y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(transformador.values()))

from matplotlib.pyplot import figure
disp.plot()
plt.show()

# hyperparameter tuning, datos

from sklearn.metrics import f1_score
print(f1_score(y_test, y_pred , average="macro"))